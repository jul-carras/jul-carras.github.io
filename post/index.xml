<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Julian Carrasquillo</title>
    <link>https://jul-carras.github.io/post/</link>
    <description>Recent content in Posts on Julian Carrasquillo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>My Name</copyright>
    <lastBuildDate>Sat, 19 Jan 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://jul-carras.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Distances Between ggmap Coordinates using gmapdistance</title>
      <link>https://jul-carras.github.io/2019/01/19/ggmap_distances/</link>
      <pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://jul-carras.github.io/2019/01/19/ggmap_distances/</guid>
      <description>Hi there! It’s been a while! The semester finally ended, so I’ve got some extra time until the next batch of classes start.
Here is a next-step analysis jumping off of the web scraping and mapping post from a couple of months back. Showing points on a map is great for big picture visualizations, but what if we need to know a little more? Maybe we’re interested in relationships between points.</description>
    </item>
    
    <item>
      <title>Data Collection - Intercompany ShareDrive</title>
      <link>https://jul-carras.github.io/2018/09/10/share_collection/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://jul-carras.github.io/2018/09/10/share_collection/</guid>
      <description>Data collection can get really messy. Rarely are we lucky enough to get a perfectly tidy data set right out of the box. Building and cleaning data sets is becoming a favorite task for me because I am able to contribute unique information to my team using super interesting methods, paving the way for new problems to be solved. In this scenario, the data that was needed rested in an internal company ShareDrive.</description>
    </item>
    
    <item>
      <title>Web Scraping and Mapping</title>
      <link>https://jul-carras.github.io/2018/08/20/scraping_mapping/</link>
      <pubDate>Mon, 20 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://jul-carras.github.io/2018/08/20/scraping_mapping/</guid>
      <description>Web scraping is a fun way to build data sets for analyses. Mapping is a great way to get an almost-literal 30 thousand mile view of a market, setting the stage for exploring potential opportunities. For a recent assignment, I built a map showing Dillard’s department stores along with the locations of 2 other retailers we’re associated with.
With guidance from this post by Saurav Kaushik, I used the Selector Gadget tool, which is a Chrome add-on that extracts out XPath and CSS selectors directly on a website.</description>
    </item>
    
    <item>
      <title>A/B Testing Case Study</title>
      <link>https://jul-carras.github.io/2018/08/01/test-ab/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://jul-carras.github.io/2018/08/01/test-ab/</guid>
      <description>When making updates to your website, it’s hard to know whether or not a change caused an improvement in your KPIs. An A/B Test provides a statistical approach to validate any findings.
I got the opportunity to try out an A/B testing analysis using some fabricated traffic data, along with a hypothesis to check. It’s important to know that there is a ton of front end work to do this right.</description>
    </item>
    
    <item>
      <title>Finally got a site up</title>
      <link>https://jul-carras.github.io/2018/07/30/2018-07-30-first/</link>
      <pubDate>Mon, 30 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://jul-carras.github.io/2018/07/30/2018-07-30-first/</guid>
      <description>Consider it an early birthday present to myself.While my summer courseload is winding down, I wanted to spend some time putting together a site. Most folks in the data science community suggest some type of presence - partially for visibility, but mostly to get your thoughts and projects in one place. I’ve done my fair share of googling how-to-do-this-thing-in-R, so it’s about time I contribute back.
This site is built using Yihui Xie’s Blogdown package.</description>
    </item>
    
  </channel>
</rss>